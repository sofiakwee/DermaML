{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2023 06/16 REMBG\n",
    "\n",
    "*Last Updated*: 2023-06-16\n",
    "\n",
    "### Authors\n",
    "* Hannah Zhang (hannahzhang@ucsb.edu)\n",
    "\n",
    "\n",
    "### Overview\n",
    "This Jupyter notebook is intended to demonstrate\n",
    "\n",
    "* generating hand outline from image\n",
    "* green screen removal\n",
    "\n",
    "### Key Results\n",
    "\n",
    "The key results of this experiment are ...\n",
    "\n",
    "- Rembg algorithm is the best method for green screen removal, generating quick, accurate results for foreground extraction with a simple call function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16B45EFF-7F1D-4437-B8FA-C7D4ADBF4F92.jpeg\n",
      "7F301A45-1207-4B6A-A05A-72B320B25E95.jpeg\n",
      "6C550AAE-8181-41AA-829C-B42D255A9E2F.jpeg\n",
      "5A7E3A5F-334A-4C8D-9E0D-BD435389C81E.jpeg\n",
      "image007.jpg\n",
      "E4FE4EBA-68AA-434C-8260-54646D0C4AC3.jpeg\n"
     ]
    }
   ],
   "source": [
    "#load sample images\n",
    "images = []\n",
    "def load_images(foldername):\n",
    "    for filename in os.listdir(foldername):\n",
    "        if filename == \".DS_Store\":\n",
    "            continue\n",
    "        input = Image.open(os.path.join(foldername,filename))\n",
    "        print(filename)\n",
    "        \n",
    "        if input is not None:\n",
    "            images.append(input)\n",
    "    return images\n",
    "img_list = load_images(\"/Users/hannahzhang/Downloads/test_ims/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rembg Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rembg import remove\n",
    "import easygui\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_ims = []\n",
    "\n",
    "for im in images:\n",
    "    output = remove(im)\n",
    "    removed_ims.append(output)\n",
    "    output.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deeplabv3_resnet50\n",
    "\n",
    "- model takes a long time to run\n",
    "- didn't produce desirable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "  model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)\n",
    "  model.eval()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transparent_foreground(pic, mask):\n",
    "  b, g, r = cv2.split(np.array(pic).astype('uint8'))\n",
    "  a = np.ones(mask.shape, dtype='uint8') * 255\n",
    "  alpha_im = cv2.merge([b, g, r, a], 4)\n",
    "  bg = np.zeros(alpha_im.shape)\n",
    "  new_mask = np.stack([mask, mask, mask, mask], axis=2)\n",
    "  foreground = np.where(new_mask, alpha_im, bg).astype(np.uint8)\n",
    "\n",
    "  return foreground\n",
    "\n",
    "def remove_background(model, input_image):\n",
    "  input_image = Image.open(input_image)\n",
    "  preprocess = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "  ])\n",
    "\n",
    "  input_tensor = preprocess(input_image)\n",
    "  input_batch = input_tensor.unsqueeze(0) \n",
    "\n",
    "  if torch.cuda.is_available():\n",
    "      input_batch = input_batch.to('cuda')\n",
    "      model.to('cuda')\n",
    "\n",
    "  with torch.no_grad():\n",
    "      output = model(input_batch)['out'][0]\n",
    "  output_predictions = output.argmax(0)\n",
    "  \n",
    "  mask = output_predictions.byte().cpu().numpy()\n",
    "  background = np.zeros(mask.shape)\n",
    "  bin_mask = np.where(mask, 255, background).astype(np.uint8)\n",
    "\n",
    "  foreground = make_transparent_foreground(input_image ,bin_mask)\n",
    "\n",
    "  return foreground, bin_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/hannahzhang/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/Users/hannahzhang/Library/Caches/pypoetry/virtualenvs/dermaml-FwaJfN4Y-py3.8/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/hannahzhang/Library/Caches/pypoetry/virtualenvs/dermaml-FwaJfN4Y-py3.8/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'input_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Applications/DermaML/notebooks/2023-06-16-HZ-Rembg.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Applications/DermaML/notebooks/2023-06-16-HZ-Rembg.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m deeplab_model \u001b[39m=\u001b[39m load_model()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Applications/DermaML/notebooks/2023-06-16-HZ-Rembg.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m foreground, bin_mask \u001b[39m=\u001b[39m remove_background(deeplab_model, input_image)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_image' is not defined"
     ]
    }
   ],
   "source": [
    "deeplab_model = load_model()\n",
    "foreground, bin_mask = remove_background(deeplab_model, input_image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erosion and Dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(input_image)\n",
    "  \n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "  \n",
    "img_erosion = cv2.erode(img, kernel, iterations=1)\n",
    "img_dilation = cv2.dilate(img, kernel, iterations=1)\n",
    "  \n",
    "cv2.imshow('Input', img)\n",
    "cv2.imshow('Erosion', img_erosion)\n",
    "cv2.imshow('Dilation', img_dilation)\n",
    "  \n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(img):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_canny = cv2.Canny(img_gray, 12, 54)\n",
    "    kernel = np.ones((3, 3))\n",
    "    img_dilate = cv2.dilate(img_canny, kernel, iterations=10)\n",
    "    img_erode = cv2.erode(img_dilate, kernel, iterations=8)\n",
    "    return img_erode\n",
    "\n",
    "img = cv2.imread(input_image)\n",
    "contours, _ = cv2.findContours(process(img), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "cv2.drawContours(img, contours, -1, (0, 255, 0), 2)\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dermaml-FwaJfN4Y-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
