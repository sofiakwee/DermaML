{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2023 06/16 REMBG\n",
    "\n",
    "*Last Updated*: 2023-06-16\n",
    "\n",
    "### Authors\n",
    "* Hannah Zhang (hannahzhang@ucsb.edu)\n",
    "\n",
    "\n",
    "### Overview\n",
    "This Jupyter notebook is intended to demonstrate\n",
    "\n",
    "* generating hand outline from image, green screen removal using Rembg algorithm, Deeplabv3, and erosion/dilation\n",
    "\n",
    "\n",
    "\n",
    "### Key Results\n",
    "\n",
    "- Rembg algorithm is the best method for green screen removal, generating quick, accurate results for foreground extraction with a simple call function\n",
    "\n",
    "- Deeplabv3 takes a long time to run and didn't produce optimal results\n",
    "\n",
    "- Erosion/ dilation does not remove green screen, only enhances hand outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load sample images\n",
    "images = []\n",
    "def load_images(foldername):\n",
    "    for filename in os.listdir(foldername):\n",
    "        if filename == \".DS_Store\":\n",
    "            continue\n",
    "        input = Image.open(os.path.join(foldername,filename))\n",
    "        print(filename)\n",
    "        \n",
    "        if input is not None:\n",
    "            images.append(input)\n",
    "    return images\n",
    "img_list = load_images(\"/Users/hannahzhang/Downloads/test_ims/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rembg Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rembg import remove\n",
    "import easygui\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_ims = []\n",
    "\n",
    "for im in images:\n",
    "    output = remove(im)\n",
    "    removed_ims.append(output)\n",
    "    output.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deeplabv3_resnet50\n",
    "\n",
    "- model takes a long time to run\n",
    "- didn't produce desirable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "  model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)\n",
    "  model.eval()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transparent_foreground(pic, mask):\n",
    "  b, g, r = cv2.split(np.array(pic).astype('uint8'))\n",
    "  a = np.ones(mask.shape, dtype='uint8') * 255\n",
    "  alpha_im = cv2.merge([b, g, r, a], 4)\n",
    "  bg = np.zeros(alpha_im.shape)\n",
    "  new_mask = np.stack([mask, mask, mask, mask], axis=2)\n",
    "  foreground = np.where(new_mask, alpha_im, bg).astype(np.uint8)\n",
    "\n",
    "  return foreground\n",
    "\n",
    "def remove_background(model, input_image):\n",
    "  input_image = Image.open(input_image)\n",
    "  preprocess = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "  ])\n",
    "\n",
    "  input_tensor = preprocess(input_image)\n",
    "  input_batch = input_tensor.unsqueeze(0) \n",
    "\n",
    "  if torch.cuda.is_available():\n",
    "      input_batch = input_batch.to('cuda')\n",
    "      model.to('cuda')\n",
    "\n",
    "  with torch.no_grad():\n",
    "      output = model(input_batch)['out'][0]\n",
    "  output_predictions = output.argmax(0)\n",
    "  \n",
    "  mask = output_predictions.byte().cpu().numpy()\n",
    "  background = np.zeros(mask.shape)\n",
    "  bin_mask = np.where(mask, 255, background).astype(np.uint8)\n",
    "\n",
    "  foreground = make_transparent_foreground(input_image ,bin_mask)\n",
    "\n",
    "  return foreground, bin_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplab_model = load_model()\n",
    "foreground, bin_mask = remove_background(deeplab_model, input_image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erosion and Dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(input_image)\n",
    "  \n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "  \n",
    "img_erosion = cv2.erode(img, kernel, iterations=1)\n",
    "img_dilation = cv2.dilate(img, kernel, iterations=1)\n",
    "  \n",
    "cv2.imshow('Input', img)\n",
    "cv2.imshow('Erosion', img_erosion)\n",
    "cv2.imshow('Dilation', img_dilation)\n",
    "  \n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(img):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_canny = cv2.Canny(img_gray, 12, 54)\n",
    "    kernel = np.ones((3, 3))\n",
    "    img_dilate = cv2.dilate(img_canny, kernel, iterations=10)\n",
    "    img_erode = cv2.erode(img_dilate, kernel, iterations=8)\n",
    "    return img_erode\n",
    "\n",
    "img = cv2.imread(input_image)\n",
    "contours, _ = cv2.findContours(process(img), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "cv2.drawContours(img, contours, -1, (0, 255, 0), 2)\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dermaml-FwaJfN4Y-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
